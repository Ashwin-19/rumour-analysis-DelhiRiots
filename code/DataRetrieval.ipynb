{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataRetrieval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ytrlh98CVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "import json\n",
        "import twint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtdzYza0VOC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# handles of Delhi Police\n",
        "Accounts = ['DelhiPolice', 'DCPSouthDelhi', 'CPDelhi', 'DCPNewDelhi', 'DcpNorthDelhi', 'DCPCentralDelhi', 'DCPNWestDelhi', 'DCPNEastDelhi', 'dcp_outernorth', 'DCPEastDelhi', 'DCPSEastDelhi', 'dcp_southwest', 'DCPWestDelhi']\n",
        "# possible location keywords\n",
        "Locations = ['Jaffrabad', 'Jafrabad', 'Jaffraabad','Jaaffrabad']\n",
        "\n",
        "# generate Search Queries\n",
        "Search_Queries = []\n",
        "for account in Accounts:\n",
        "  for location in Locations:\n",
        "      Search_Queries.append('@' + account + ' ' + location)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz6KY-hmbUYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retrieve tweets\n",
        "client = twint.Config()\n",
        "client.Since = '2020-02-01'\n",
        "client.Until = '2020-03-06'\n",
        "client.Lang = 'en'\n",
        "client.Pandas = True\n",
        "\n",
        "# list of dataframes\n",
        "Data = []\n",
        "\n",
        "for query in Search_Queries:\n",
        "  client.Search = query\n",
        "  twint.run.Search(client)\n",
        "  Tweets = twint.storage.panda.Tweets_df\n",
        "  Data.append(Tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz6nAW7seFcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add all tweets to single dataframe\n",
        "Tweets = Data[0]\n",
        "for tweets in Data:\n",
        "  Tweets = Tweets.append(tweets)\n",
        "\n",
        "# remove duplicates\n",
        "Tweets = Tweets.drop_duplicates(subset='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkdFRTnDWq6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove redundant columns\n",
        "Tweets = Tweets.drop(['cashtags','search','translate', 'trans_src', 'trans_dest'],axis=1)\n",
        "\n",
        "# replace empty entries with NaNs\n",
        "Tweets.replace(r'^\\s*$', np.nan, regex=True)\n",
        "Tweets.to_csv('DatabaseTweets.csv') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}